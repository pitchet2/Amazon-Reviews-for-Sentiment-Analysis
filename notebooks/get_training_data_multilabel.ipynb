{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import spacy\n",
    "from spacy.tokens import DocBin\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import bz2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = bz2.BZ2File('../data/train.ft.txt.bz2')\n",
    "train_lines = train.readlines() \n",
    "train_lines = [x.decode('utf-8') for x in train_lines]\n",
    "train_labels = [i.split(\" \")[0] for i in train_lines]\n",
    "train_texts = [\" \".join(i.split(\" \")[1:]) for i in train_lines]\n",
    "df_train = pd.DataFrame(columns= [\"Labels\", \"Features\"])\n",
    "df_train['Labels'] = train_labels\n",
    "df_train['Features'] = train_texts\n",
    "\n",
    "test = bz2.BZ2File('../data/test.ft.txt.bz2')\n",
    "test_lines = test.readlines() \n",
    "test_lines = [x.decode('utf-8') for x in test_lines]\n",
    "test_labels = [i.split(\" \")[0] for i in test_lines]\n",
    "test_texts = [\" \".join(i.split(\" \")[1:]) for i in test_lines]\n",
    "df_test = pd.DataFrame(columns= [\"Labels\", \"Features\"])\n",
    "df_test['Labels'] = test_labels\n",
    "df_test['Features'] = test_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_spacy = df_train[df_train['Features'].apply(lambda x: len(x.split()) < 100)].groupby('Labels', group_keys=False).apply(lambda x: x.sample(100000))\n",
    "df_test_spacy = df_test[df_test['Features'].apply(lambda x: len(x.split()) < 100)].groupby('Labels', group_keys=False).apply(lambda x: x.sample(100000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cats(labels: list(),labels_dict: dict):\n",
    "    \"\"\"This will take a label and a dictionary and return a dictionary for spacy.Doc.doc.cats\n",
    "\n",
    "    Args:\n",
    "        label (str): label of current text\n",
    "        labels_dict (dict): default labels dict to create label\n",
    "\n",
    "    Returns:\n",
    "        temp_dict: dictionary label for current text\n",
    "    \"\"\"\n",
    "    temp_dict = labels_dict.copy()\n",
    "    for label in labels:\n",
    "        temp_dict[label] = 1.0\n",
    "    return temp_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = df_train['Labels'].unique().tolist()\n",
    "labels_dict = {i:0.0 for i in labels}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.blank(\"en\")\n",
    "db = DocBin()\n",
    "column = \"Features\"\n",
    "\n",
    "for i,row in df_train_spacy.iterrows():\n",
    "    doc = nlp.make_doc(row[column])    \n",
    "    temp_dict = get_cats(labels = [row['Labels']],labels_dict = labels_dict)\n",
    "    doc.cats = temp_dict\n",
    "    db.add(doc)\n",
    "db.to_disk(\"../textcat_multilabel/corpus/train.spacy\")\n",
    "\n",
    "db=DocBin()\n",
    "for i,row in df_test_spacy.iterrows():\n",
    "    doc = nlp.make_doc(row[column])    \n",
    "    temp_dict = get_cats(labels = [row['Labels']],labels_dict = labels_dict)\n",
    "    doc.cats = temp_dict    \n",
    "    db.add(doc)\n",
    "db.to_disk(\"../textcat_multilabel/corpus/dev.spacy\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 ('nlp_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "519ab88ae1ce4d64b3060827bd011b622330af4988054840d71c5cfa657dbaaf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
